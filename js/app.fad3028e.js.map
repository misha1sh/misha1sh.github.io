{"version":3,"file":"js/app.fad3028e.js","mappings":"gJAEAA,EAAAA,EAAAA,IAAOC,E,iHCFP,yqX,6bC6DAC,EAAAA,IAAAA,KAAAA,UAAqB,CACnB,gBAAiB,oBACjB,yBAA2B,6BAC3B,qBAAuB,yBACvB,8BAAgC,mCAMlC,MAAMC,EACFC,MAAM,gEACDC,MAAKC,GAAYA,EAASC,gBAC1BF,MAAKG,GACKC,EAAAA,iBAAAA,OAAwBD,EAC3B,CAAEE,mBAAoB,CAAC,YAMjCC,GAAkBC,EAAAA,EAAAA,GAAY,CAChCC,SAAU,cAKdC,EAAe,CACbC,KAAM,aACNC,MAAO,CACP,EACAC,OACE,MAAO,CACLC,MAAO,GACPC,QAAS,GACTC,aAAc,GACdC,gBAAgBC,EAAAA,EAAAA,KAAI,GACpBC,WAAWD,EAAAA,EAAAA,KAAI,GAEnB,EACAE,UAEEC,eAAeC,IACbC,QAAQC,IAAI,OACZ,MAAMC,QAAgBlB,QAChBkB,EAAQC,YAAY,YAC1B,MAAMC,QAAgB5B,EAEtBsB,eAAeO,EAAMC,GACnB,MAAMC,EAAMD,EAAcE,UAAU,OAE9BC,EAAS,IAAIC,EAAAA,OAAO,UAAWH,EAAIjB,KAAM,CAAC,EAAI,GAAI,MAClDqB,EAAOP,EAAQL,IAAI,CAACR,MAAOkB,IAC3BG,SAAgBD,GAAMC,OAC5B,OAAOC,MAAMC,KAAKF,EAAOtB,KAC3B,OAEMY,EAAQa,iBAAiB,UAAW,CACxC,MAASV,IAGXH,EAAQc,QAAQC,IAAI,OAAQ,SAC5BjB,QAAQC,UAAUC,EAAQgB,eAAeC,EAAO,uCAClD,CAtBAnB,QAAQC,IAAI,WAuBZF,IAAMrB,MAAK,KACT0C,KAAK1B,gBAAiB,CAAK,IAE7BV,EAAgBN,MAAKwB,IACnBF,QAAQC,IAAIC,EAAQ,GAGxB,EACAmB,QAAS,CACPvB,oBACEsB,KAAK1B,gBAAiB,EAEtB,MAAM4B,EAAMF,KAAK7B,MAEXW,QAAgBlB,EACtBkB,EAAQc,QAAQC,IAAI,OAAQK,GAC5B,MAAMC,QAAYrB,EAAQgB,eAAeC,EAAO,uCAEhDC,KAAK5B,QAAU+B,EACfH,KAAK3B,cAAe+B,EAAAA,EAAAA,IAAUF,EAAKC,GAEnCH,KAAK1B,gBAAiB,CACxB,EACA+B,mBACEL,KAAK7B,MAAQ6B,KAAK7B,MAAMmC,WAAW,IAAK,IAAIA,WAAW,IAAK,GAC9D,I,wqDCnJJ,MAAMC,EAAc,EAEpB,QHGA,GACAvC,KAAM,MACNwC,WAAY,CACVC,KAAIA,I,QIJN,MAAM,GAA2B,OAAgB,EAAQ,CAAC,CAAC,SAASC,KAEpE,QCNA,MAAMC,GAAMC,EAAAA,EAAAA,IAAUC,GACtBF,EAAIG,MAAM,O,GCHNC,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBE,IAAjBD,EACH,OAAOA,EAAaE,QAGrB,IAAIC,EAASN,EAAyBE,GAAY,CAGjDG,QAAS,CAAC,GAOX,OAHAE,EAAoBL,GAAUI,EAAQA,EAAOD,QAASJ,GAG/CK,EAAOD,OACf,CAGAJ,EAAoBO,EAAID,E,WCzBxB,IAAIE,EAAW,GACfR,EAAoBS,EAAI,SAASC,EAAQC,EAAUC,EAAIC,GACtD,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAASC,EAAI,EAAGA,EAAIR,EAASS,OAAQD,IAAK,CACrCL,EAAWH,EAASQ,GAAG,GACvBJ,EAAKJ,EAASQ,GAAG,GACjBH,EAAWL,EAASQ,GAAG,GAE3B,IAJA,IAGIE,GAAY,EACPC,EAAI,EAAGA,EAAIR,EAASM,OAAQE,MACpB,EAAXN,GAAsBC,GAAgBD,IAAaO,OAAOC,KAAKrB,EAAoBS,GAAGa,OAAM,SAASC,GAAO,OAAOvB,EAAoBS,EAAEc,GAAKZ,EAASQ,GAAK,IAChKR,EAASa,OAAOL,IAAK,IAErBD,GAAY,EACTL,EAAWC,IAAcA,EAAeD,IAG7C,GAAGK,EAAW,CACbV,EAASgB,OAAOR,IAAK,GACrB,IAAIS,EAAIb,SACET,IAANsB,IAAiBf,EAASe,EAC/B,CACD,CACA,OAAOf,CArBP,CAJCG,EAAWA,GAAY,EACvB,IAAI,IAAIG,EAAIR,EAASS,OAAQD,EAAI,GAAKR,EAASQ,EAAI,GAAG,GAAKH,EAAUG,IAAKR,EAASQ,GAAKR,EAASQ,EAAI,GACrGR,EAASQ,GAAK,CAACL,EAAUC,EAAIC,EAwB/B,C,eC5BAb,EAAoB0B,EAAI,SAASrB,GAChC,IAAIsB,EAAStB,GAAUA,EAAOuB,WAC7B,WAAa,OAAOvB,EAAO,UAAY,EACvC,WAAa,OAAOA,CAAQ,EAE7B,OADAL,EAAoB6B,EAAEF,EAAQ,CAAEG,EAAGH,IAC5BA,CACR,C,eCPA,IACII,EADAC,EAAWZ,OAAOa,eAAiB,SAASC,GAAO,OAAOd,OAAOa,eAAeC,EAAM,EAAI,SAASA,GAAO,OAAOA,EAAIC,SAAW,EAQpInC,EAAoBoC,EAAI,SAASC,EAAOC,GAEvC,GADU,EAAPA,IAAUD,EAAQrD,KAAKqD,IAChB,EAAPC,EAAU,OAAOD,EACpB,GAAoB,kBAAVA,GAAsBA,EAAO,CACtC,GAAW,EAAPC,GAAaD,EAAMT,WAAY,OAAOS,EAC1C,GAAW,GAAPC,GAAoC,oBAAfD,EAAM/F,KAAqB,OAAO+F,CAC5D,CACA,IAAIE,EAAKnB,OAAOoB,OAAO,MACvBxC,EAAoByB,EAAEc,GACtB,IAAIE,EAAM,CAAC,EACXV,EAAiBA,GAAkB,CAAC,KAAMC,EAAS,CAAC,GAAIA,EAAS,IAAKA,EAASA,IAC/E,IAAI,IAAIU,EAAiB,EAAPJ,GAAYD,EAAyB,iBAAXK,KAAyBX,EAAeY,QAAQD,GAAUA,EAAUV,EAASU,GACxHtB,OAAOwB,oBAAoBF,GAASG,SAAQ,SAAStB,GAAOkB,EAAIlB,GAAO,WAAa,OAAOc,EAAMd,EAAM,CAAG,IAI3G,OAFAkB,EAAI,WAAa,WAAa,OAAOJ,CAAO,EAC5CrC,EAAoB6B,EAAEU,EAAIE,GACnBF,CACR,C,eCxBAvC,EAAoB6B,EAAI,SAASzB,EAAS0C,GACzC,IAAI,IAAIvB,KAAOuB,EACX9C,EAAoB+C,EAAED,EAAYvB,KAASvB,EAAoB+C,EAAE3C,EAASmB,IAC5EH,OAAO4B,eAAe5C,EAASmB,EAAK,CAAE0B,YAAY,EAAMC,IAAKJ,EAAWvB,IAG3E,C,eCPAvB,EAAoBmD,EAAI,CAAC,EAGzBnD,EAAoBoD,EAAI,SAASC,GAChC,OAAOC,QAAQC,IAAInC,OAAOC,KAAKrB,EAAoBmD,GAAGK,QAAO,SAASC,EAAUlC,GAE/E,OADAvB,EAAoBmD,EAAE5B,GAAK8B,EAASI,GAC7BA,CACR,GAAG,IACJ,C,eCPAzD,EAAoB0D,EAAI,SAASL,GAEhC,MAAO,MAAQA,EAAU,IAAM,CAAC,GAAK,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,YAAYA,GAAW,KACrM,C,eCHArD,EAAoB2D,SAAW,SAASN,GAGxC,C,eCJArD,EAAoB4D,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAO7E,MAAQ,IAAI8E,SAAS,cAAb,EAChB,CAAE,MAAOV,GACR,GAAsB,kBAAXW,OAAqB,OAAOA,MACxC,CACA,CAPuB,E,eCAxB/D,EAAoB+C,EAAI,SAASb,EAAK8B,GAAQ,OAAO5C,OAAO6C,UAAUC,eAAeC,KAAKjC,EAAK8B,EAAO,C,eCAtG,IAAII,EAAa,CAAC,EACdC,EAAoB,WAExBrE,EAAoBsE,EAAI,SAASC,EAAKC,EAAMjD,EAAK8B,GAChD,GAAGe,EAAWG,GAAQH,EAAWG,GAAKE,KAAKD,OAA3C,CACA,IAAIE,EAAQC,EACZ,QAAWxE,IAARoB,EAEF,IADA,IAAIqD,EAAUC,SAASC,qBAAqB,UACpC9D,EAAI,EAAGA,EAAI4D,EAAQ3D,OAAQD,IAAK,CACvC,IAAI+D,EAAIH,EAAQ5D,GAChB,GAAG+D,EAAEC,aAAa,QAAUT,GAAOQ,EAAEC,aAAa,iBAAmBX,EAAoB9C,EAAK,CAAEmD,EAASK,EAAG,KAAO,CACpH,CAEGL,IACHC,GAAa,EACbD,EAASG,SAASI,cAAc,UAEhCP,EAAOQ,QAAU,QACjBR,EAAOS,QAAU,IACbnF,EAAoBoF,IACvBV,EAAOW,aAAa,QAASrF,EAAoBoF,IAElDV,EAAOW,aAAa,eAAgBhB,EAAoB9C,GACxDmD,EAAOY,IAAMf,GAEdH,EAAWG,GAAO,CAACC,GACnB,IAAIe,EAAmB,SAASC,EAAMC,GAErCf,EAAOgB,QAAUhB,EAAOiB,OAAS,KACjCC,aAAaT,GACb,IAAIU,EAAUzB,EAAWG,GAIzB,UAHOH,EAAWG,GAClBG,EAAOoB,YAAcpB,EAAOoB,WAAWC,YAAYrB,GACnDmB,GAAWA,EAAQhD,SAAQ,SAASjC,GAAM,OAAOA,EAAG6E,EAAQ,IACzDD,EAAM,OAAOA,EAAKC,EACtB,EACIN,EAAUa,WAAWT,EAAiBU,KAAK,UAAM9F,EAAW,CAAE+F,KAAM,UAAWC,OAAQzB,IAAW,MACtGA,EAAOgB,QAAUH,EAAiBU,KAAK,KAAMvB,EAAOgB,SACpDhB,EAAOiB,OAASJ,EAAiBU,KAAK,KAAMvB,EAAOiB,QACnDhB,GAAcE,SAASuB,KAAKC,YAAY3B,EAnCkB,CAoC3D,C,eCvCA1E,EAAoByB,EAAI,SAASrB,GACX,qBAAXkG,QAA0BA,OAAOC,aAC1CnF,OAAO4B,eAAe5C,EAASkG,OAAOC,YAAa,CAAElE,MAAO,WAE7DjB,OAAO4B,eAAe5C,EAAS,aAAc,CAAEiC,OAAO,GACvD,C,eCNArC,EAAoBwG,EAAI,G,eCKxB,IAAIC,EAAkB,CACrB,IAAK,GAGNzG,EAAoBmD,EAAEhC,EAAI,SAASkC,EAASI,GAE1C,IAAIiD,EAAqB1G,EAAoB+C,EAAE0D,EAAiBpD,GAAWoD,EAAgBpD,QAAWlD,EACtG,GAA0B,IAAvBuG,EAGF,GAAGA,EACFjD,EAASgB,KAAKiC,EAAmB,QAC3B,CAGL,IAAIC,EAAU,IAAIrD,SAAQ,SAASsD,EAASC,GAAUH,EAAqBD,EAAgBpD,GAAW,CAACuD,EAASC,EAAS,IACzHpD,EAASgB,KAAKiC,EAAmB,GAAKC,GAGtC,IAAIpC,EAAMvE,EAAoBwG,EAAIxG,EAAoB0D,EAAEL,GAEpDyD,EAAQ,IAAIC,MACZC,EAAe,SAASvB,GAC3B,GAAGzF,EAAoB+C,EAAE0D,EAAiBpD,KACzCqD,EAAqBD,EAAgBpD,GACX,IAAvBqD,IAA0BD,EAAgBpD,QAAWlD,GACrDuG,GAAoB,CACtB,IAAIO,EAAYxB,IAAyB,SAAfA,EAAMS,KAAkB,UAAYT,EAAMS,MAChEgB,EAAUzB,GAASA,EAAMU,QAAUV,EAAMU,OAAOb,IACpDwB,EAAMK,QAAU,iBAAmB9D,EAAU,cAAgB4D,EAAY,KAAOC,EAAU,IAC1FJ,EAAM9J,KAAO,iBACb8J,EAAMZ,KAAOe,EACbH,EAAMM,QAAUF,EAChBR,EAAmB,GAAGI,EACvB,CAEF,EACA9G,EAAoBsE,EAAEC,EAAKyC,EAAc,SAAW3D,EAASA,EAE/D,CAEH,EAUArD,EAAoBS,EAAEU,EAAI,SAASkC,GAAW,OAAoC,IAA7BoD,EAAgBpD,EAAgB,EAGrF,IAAIgE,EAAuB,SAASC,EAA4BpK,GAC/D,IAKI+C,EAAUoD,EALV1C,EAAWzD,EAAK,GAChBqK,EAAcrK,EAAK,GACnBsK,EAAUtK,EAAK,GAGI8D,EAAI,EAC3B,GAAGL,EAAS8G,MAAK,SAASC,GAAM,OAA+B,IAAxBjB,EAAgBiB,EAAW,IAAI,CACrE,IAAIzH,KAAYsH,EACZvH,EAAoB+C,EAAEwE,EAAatH,KACrCD,EAAoBO,EAAEN,GAAYsH,EAAYtH,IAGhD,GAAGuH,EAAS,IAAI9G,EAAS8G,EAAQxH,EAClC,CAEA,IADGsH,GAA4BA,EAA2BpK,GACrD8D,EAAIL,EAASM,OAAQD,IACzBqC,EAAU1C,EAASK,GAChBhB,EAAoB+C,EAAE0D,EAAiBpD,IAAYoD,EAAgBpD,IACrEoD,EAAgBpD,GAAS,KAE1BoD,EAAgBpD,GAAW,EAE5B,OAAOrD,EAAoBS,EAAEC,EAC9B,EAEIiH,EAAqBC,KAAK,uBAAyBA,KAAK,wBAA0B,GACtFD,EAAmB9E,QAAQwE,EAAqBpB,KAAK,KAAM,IAC3D0B,EAAmBlD,KAAO4C,EAAqBpB,KAAK,KAAM0B,EAAmBlD,KAAKwB,KAAK0B,G,ICpFvF,IAAIE,EAAsB7H,EAAoBS,OAAEN,EAAW,CAAC,MAAM,WAAa,OAAOH,EAAoB,KAAO,IACjH6H,EAAsB7H,EAAoBS,EAAEoH,E","sources":["webpack://app-web/./src/App.vue","webpack://app-web/./src/assets/code.py","webpack://app-web/./src/components/Main.vue","webpack://app-web/./src/components/Main.vue?4fee","webpack://app-web/./src/App.vue?7ccd","webpack://app-web/./src/main.js","webpack://app-web/webpack/bootstrap","webpack://app-web/webpack/runtime/chunk loaded","webpack://app-web/webpack/runtime/compat get default export","webpack://app-web/webpack/runtime/create fake namespace object","webpack://app-web/webpack/runtime/define property getters","webpack://app-web/webpack/runtime/ensure chunk","webpack://app-web/webpack/runtime/get javascript chunk filename","webpack://app-web/webpack/runtime/get mini-css chunk filename","webpack://app-web/webpack/runtime/global","webpack://app-web/webpack/runtime/hasOwnProperty shorthand","webpack://app-web/webpack/runtime/load script","webpack://app-web/webpack/runtime/make namespace object","webpack://app-web/webpack/runtime/publicPath","webpack://app-web/webpack/runtime/jsonp chunk loading","webpack://app-web/webpack/startup"],"sourcesContent":["<template>\n  <!-- <img alt=\"Vue logo\" src=\"./assets/logo.png\"> -->\n<Main/>\n</template>\n\n<script>\nimport Main from './components/Main.vue'\n\nexport default {\nname: 'App',\ncomponents: {\n  Main\n}\n}\n</script>\n\n<style>\n#app {\nmargin: 100px;\n}\n/*\nfont-family: Avenir, Helvetica, Arial, sans-serif;\n-webkit-font-smoothing: antialiased;\n-moz-osx-font-smoothing: grayscale;\ntext-align: center;\ncolor: #2c3e50;\n\n} */\n</style>\nd","export default \"import micropip\\n\\nimport jsinfer\\n\\nmicropip.add_mock_package(\\\"docopt\\\", \\\"0.6.2\\\", modules = {\\n    \\\"docopt\\\": \\\"\\\"\\\"\\n        docopt = 1\\n    \\\"\\\"\\\"\\n})\\n\\nfor i in \\\"pymorphy3 numpy navec setuptools razdel\\\".split():\\n    await micropip.install(i)\\n# await micropip.install(\\\"\\\")/\\n# await micropip.install(\\\"sacremoses\\\")\\n# await micropip.install(\\\"\\\")\\n# await micropip.install(\\\"\\\")\\n# await micropip.install(\\\"\\\")\\n\\nimport numpy as np\\nimport random\\nimport pymorphy3\\nimport numpy as np\\nimport math\\nimport pickle\\nfrom razdel import tokenize\\n\\nNO_PUNCT = 0\\nfrom navec import Navec\\nimport itertools\\n# from sacremoses import MosesPunctNormalizer\\nfrom pyodide.http import pyfetch\\nimport os\\n\\n# punctuation_normalizer = MosesPunctNormalizer('ru')\\n\\nmorph = pymorphy3.MorphAnalyzer()\\n\\nasync def download_file(file, url):\\n    file_path = os.path.join(\\\"./\\\", file)\\n    if os.path.isfile(file_path):\\n        return file_path\\n    print(\\\"donwloading\\\", file, \\\"to\\\", file_path)\\n    # url = BASE_URL + file\\n    response = await pyfetch(url)\\n    with open(file, \\\"wb\\\") as f:\\n        f.write(await response.bytes())\\n    return file_path\\n\\nnavec_path = await download_file('hudlit_12B_500K_300d_100q.tar',\\n                                 \\\"https://storage.yandexcloud.net/misha-sh-objects/hudlit_12B_500K_300d_100q.tar\\\")\\n        # \\\"/hudlit_12B_500K_300d_100q.tar\\\")\\nnavec = Navec.load(navec_path)\\n\\nresponse = await pyfetch(\\\"/params.pickle\\\")\\nparams = pickle.loads(await response.bytes())\\n\\nNUMPY_DTYPE = float\\nNAVEC_UNK = navec['<unk>']\\nNAVEC_UNK_TORCH = NAVEC_UNK\\nNAVEC_PAD_TORCH = navec['<pad>']\\n\\nUNDEF_TOKEN = \\\"UNDEF\\\"\\nPAD_TOKEN = \\\"PAD\\\"\\n\\n\\ndef empty_word_features(params):\\n    return np.zeros([params[\\\"TOTAL_WORD_FEATURES_CNT\\\"]],\\n                        dtype=NUMPY_DTYPE)\\n\\ndef get_navec_start_idx(params):\\n    return params['VARIANT_FEATURES_CNT'] * params['VARIANTS_CNT']\\n\\ndef pad_word_features(params):\\n    res = empty_word_features(params)\\n    res[get_navec_start_idx(params): ] = NAVEC_PAD_TORCH\\n    return res\\n\\ndef undef_word_features(params):\\n    res = empty_word_features(params)\\n    res[get_navec_start_idx(params): ] = NAVEC_UNK_TORCH\\n    return res\\n\\n\\nPNCT_TAGS = {\\n    '.': 'PUNCT_DOT',\\n    '!': 'PUNCT_DOT',\\n    '?': 'PUNCT_DOT',\\n    ',': 'PUNCT_COMMA',\\n    '-': 'PUNCT_DASH',\\n    '.':'PUNCT_DOT',\\n    '\\\"': 'PUNCT_QUOTE',\\n    #'\\\\\\\\'': 'PUNCT_QUOTE',\\n    '(': 'PUNCT_LEFT_PARENTHESIS',\\n    ')': 'PUNCT_RIGHT_PARENTHESIS',\\n}\\n\\ndef get_word_features(word, params):\\n    if word == PAD_TOKEN:\\n        return pad_word_features(params)\\n    if word == UNDEF_TOKEN:\\n        return undef_word_features(params)\\n\\n    additional_tags = []\\n\\n    res = empty_word_features(params)\\n    if not str.isalpha(word[0]):\\n        # word_punct = punctuation_normalizer(word).strip()\\n        word_punct = word.strip()[0]\\n        if word_punct in PNCT_TAGS:\\n            additional_tags.append(PNCT_TAGS[word_punct])\\n\\n    if str.isupper(word[0]):\\n        additional_tags.append('CAPITALIZED')\\n\\n    use_navec = True\\n\\n    variant_features_cnt = params['VARIANT_FEATURES_CNT']\\n    for i, variant in enumerate(morph.parse(word)[:params[\\\"VARIANTS_CNT\\\"]]):\\n        tags = variant.tag._grammemes_tuple\\n\\n        for tag in itertools.chain(tags, additional_tags):\\n            tag_index = params[\\\"feature_tags_dict\\\"].get(tag, None)\\n            if tag_index:\\n                res[i * variant_features_cnt + tag_index] = True\\n            if i == 0 and tag in params['CUT_NAVEC_TAGS_SET']:\\n                use_navec = False\\n        res[i * variant_features_cnt + params[\\\"VARIANT_PROB_IDX\\\"]] = variant.score\\n\\n\\n    if params['USE_NAVEC'] and use_navec:\\n        res[get_navec_start_idx(params): ] = navec.get(word.lower(), NAVEC_UNK)\\n\\n    return res\\n\\n\\nfrom collections import deque\\nimport random\\n\\n#https://stackoverflow.com/a/15993515\\nclass ListRandom(object):\\n    def __init__(self):\\n        self.items = []\\n\\n    def add_item(self, item):\\n        self.items.append(item)\\n\\n    def remove_item(self, position):\\n        last_item = self.items.pop()\\n        if position != len(self.items):\\n            self.items[position] = last_item\\n\\n    def __len__(self):\\n        return len(self.items)\\n\\n    def pop_random(self):\\n        assert len(self.items) > 0\\n        i = random.randrange(0, len(self.items))\\n        element = self.items[i]\\n        self.remove_item(i)\\n        return element\\n\\n\\n\\n\\nclass Stream:\\n    def __init__(self, generator):\\n        try:\\n            self.generator = iter(generator)\\n        except TypeError:\\n            self.generator = generator\\n\\n    def __iter__(self):\\n        return self\\n\\n    def __next__(self):\\n        return next(self.generator)\\n\\n    @staticmethod\\n    def repeat(element, n):\\n        def generator():\\n          for i in range(n):\\n              yield element\\n        return Stream(generator())\\n\\n    def buffered_mix(self, elements_in_buffer_count):\\n        def generator():\\n            buffer = ListRandom()\\n            it = iter(self)\\n            while True:\\n                while len(buffer) < elements_in_buffer_count:\\n                    try:\\n                        buffer.add_item(next(it))\\n                    except StopIteration:\\n                        while len(buffer) > 0:\\n                            yield buffer.pop_random()\\n                        return\\n                yield buffer.pop_random()\\n        return Stream(generator())\\n\\n\\n    @staticmethod\\n    def mix_streams(streams, weights):\\n        def generator():\\n            iters = [iter(i) for i in streams]\\n            choices = list(range(len(streams)))\\n            i = 0\\n            while True:\\n                try:\\n                    i = random.choices(choices, weights)[0]\\n                    yield next(iters[i])\\n                except StopIteration:\\n                    weights[i] = 0\\n                    if sum(weights) == 0:\\n                        return\\n        return Stream(generator())\\n\\n\\n    def chain(self, another_stream):\\n        def generator():\\n            for i in self:\\n                yield i\\n            for i in another_stream:\\n                yield i\\n        return Stream(generator())\\n\\n    def slide_window(self, window_size):\\n        res = deque()\\n        for i in self:\\n          res.append(i)\\n          if len(res) == window_size:\\n            yield Stream(res)\\n            res.popleft()\\n\\n    def skip(self, count):\\n        def generator():\\n            n = count\\n            for i in self.generator:\\n                n -= 1\\n                if n == 0: break\\n            for i in self.generator:\\n                yield i\\n        return Stream(generator())\\n\\n    def get(self, count):\\n        res = []\\n        for i in self:\\n            res.append(i)\\n            if len(res) == count:\\n                return res\\n        return res\\n\\n    def limit(self, count):\\n        def generator():\\n            n = count\\n            for i in self.generator:\\n                yield i\\n                n -= 1\\n                if n == 0: break\\n        return Stream(generator())\\n\\n    def map(self, func):\\n        def generator():\\n            for i in self.generator:\\n                yield func(i)\\n        return Stream(generator())\\n\\n    def starmap(self, func):\\n        def generator():\\n            for i in self.generator:\\n                for j in func(i):\\n                    yield j\\n        return Stream(generator())\\n\\n    def group(self, n):\\n        def generator():\\n            grouped = []\\n            for i in self.generator:\\n                grouped.append(i)\\n                if len(grouped) >= n:\\n                    yield grouped\\n                    grouped = []\\n            if len(grouped) != 0:\\n                yield grouped\\n\\n        return Stream(generator())\\n\\n\\n\\nimport functools\\nfrom collections import deque\\nimport random\\nrandom.seed(42)\\n\\n@functools.lru_cache(maxsize=128)\\ndef get_word_features_cached(word):\\n    return get_word_features(word, params)#.numpy()\\n\\nclass Substr:\\n    def __init__(self, text):\\n        self.text = text\\n    def __repr__(self) -> str:\\n        return f\\\"Substring(-1, -1, {self.text})\\\"\\n\\ndef d_as_str(d):\\n  return \\\"<\\\" + \\\" \\\".join(map(lambda text: text.text, d))+ \\\">\\\"\\n\\n\\nasync def infer_optimal(params, text):\\n  # print(\\\"INFERCENC IS WIERD\\\\n\\\" * 10)\\n  res = []\\n  last_inserted_pos = 0\\n  def sink(token, log=False):\\n    nonlocal last_inserted_pos\\n    if token.text == \\\"PAD\\\": return\\n    if log: print('sink', token)\\n    if isinstance(token, Substr):\\n      res.append(token.text)\\n      if log: print(\\\"added1 \\\", f\\\"`{token.text}`\\\", token)\\n    else:\\n      if last_inserted_pos != token.start:\\n        res.append(text[last_inserted_pos: token.start])\\n        if log: print(\\\"added2 \\\", f\\\"`{text[last_inserted_pos: token.start]}`\\\", last_inserted_pos, token.start)\\n      last_inserted_pos = token.stop\\n      res.append(token.text)\\n      if log: print(\\\"added3 \\\", f\\\"`{token.text}`\\\", token)\\n\\n  def skip(token, log=False):\\n    nonlocal last_inserted_pos\\n    last_inserted_pos = token.stop\\n    if log: print('skip', token)\\n\\n  def sink_remaining():\\n     res.append(text[last_inserted_pos:])\\n\\n\\n  async def predict_on_tokens(window_left, window_right, return_probas):\\n    features = [get_word_features_cached(i.text) for i in Stream(window_left).chain(window_right)]\\n    features_for_batch = np.stack((features, ))\\n    arr = np.ascontiguousarray(features_for_batch, dtype=np.float32)\\n    output_probas = np.array((await jsinfer.infer(arr)).to_py())\\n    # output_probas[0][0] += 2.\\n    if return_probas:\\n      return params[\\\"ID_TO_PUNCTUATION\\\"], output_probas\\n    punct_idx = np.argmax(output_probas).item()\\n    punct = params[\\\"ID_TO_PUNCTUATION\\\"][punct_idx]\\n    return punct\\n\\n\\n  window_left = deque()\\n  window_right = deque()\\n  log = False\\n  skip_next = False\\n  for i in Stream.repeat(Substr(PAD_TOKEN), params['INPUT_WORDS_CNT_LEFT']) \\\\\\n      .chain(Stream(tokenize(text))) \\\\\\n      .chain(Stream.repeat(Substr(PAD_TOKEN), params[\\\"INPUT_WORDS_CNT_RIGHT\\\"])):\\n    window_right.append(i)\\n    if len(window_right) <= params[\\\"INPUT_WORDS_CNT_RIGHT\\\"]:\\n        continue\\n    assert len(window_right) == params[\\\"INPUT_WORDS_CNT_RIGHT\\\"] + 1\\n\\n    next_ = window_right.popleft()\\n    sink(next_)\\n    window_left.append(next_)\\n    if len(window_left) < params['INPUT_WORDS_CNT_LEFT']:\\n      continue\\n\\n    assert len(window_left) == params[\\\"INPUT_WORDS_CNT_LEFT\\\"]\\n    assert len(window_right) == params[\\\"INPUT_WORDS_CNT_RIGHT\\\"]\\n\\n    if skip_next or window_right[0].text in '?!':\\n      prediction = \\\"$skip\\\"\\n    else:\\n      # params[\\\"ID_TO_PUNCTUATION\\\"], output_probas\\n      prediction = await predict_on_tokens(window_left, window_right, return_probas=False)\\n\\n\\n    #random.choice([\\\" \\\", \\\".\\\"])\\n    if log: print(d_as_str(window_left).rjust(100), prediction.center(6), d_as_str(window_right))\\n\\n    def is_replaceable_punct(punct):\\n      return punct in ',.'\\n\\n    if prediction == \\\"$skip\\\":\\n      pass\\n    elif prediction != \\\"$empty\\\":\\n      if is_replaceable_punct(window_right[0].text):\\n        if window_right[0].text != prediction:\\n          window_right[0].text = prediction\\n      else:\\n        window_left.append(Substr(prediction))\\n        sink(window_left[-1])\\n    else:\\n      if is_replaceable_punct(window_right[0].text):\\n          skip(window_right.popleft())\\n\\n    skip_next = is_replaceable_punct(window_right[0].text) or window_right[0].text in '?!'\\n\\n    while len(window_left) != params['INPUT_WORDS_CNT_LEFT'] - 1:\\n      token = window_left.popleft()\\n\\n    if log: print(d_as_str(window_left).rjust(100), \\\"      \\\", d_as_str(window_right))\\n\\n  for i in window_right:\\n    sink(i)\\n  sink_remaining()\\n  ress = \\\"\\\".join(res)\\n  return ress\";","<template>\n  <div class=\"hello\">\n    <h1>Исходный текст: </h1>\n    <n-input\n      type=\"textarea\"\n      v-model:value=\"input\"\n      placeholder=\"Исходный текст:\"\n      clearable\n      :autosize=\"{\n        minRows: 5,\n        maxRows: 20\n      }\"\n      style=\"font-size:1.2em\"\n    />\n    <n-space align=\"center\">\n      <n-button\n        type=\"info\"\n        @click=\"handleInput\"\n        :disabled=\"showLoadingBar\">Раставить пунктуацию</n-button>\n        <n-button\n      type=\"info\"\n        @click=\"clearPunctuation\"\n        :disabled=\"input.length == 0\">\n        Очистить пунктуацию из исходного текста</n-button>\n\n    <n-checkbox v-model:checked=\"show_diff\" :disabled=\"results_diff.length == 0 || showLoadingBar\">\n      Показывать разницу с исходным текстом\n    </n-checkbox>\n\n    </n-space>\n    <h1>Результаты: </h1>\n\n    <n-spin :show=\"showLoadingBar\">\n      <n-card>\n        <div v-if=\"show_diff\" style=\"font-size:1.2em\">\n          <div v-for=\"[index, part] in results_diff.entries()\" :key=\"index\" style=\"display: inline;\">\n            <div v-if=\"part.added\" style=\"background-color:#8aff8a; display: inline; white-space: pre-wrap\">{{part.value}}</div>\n            <div v-if=\"part.removed\" style=\"background-color:#ffcfcf; display: inline; white-space: pre-wrap\">{{part.value}}</div>\n            <div v-if=\"!part.added && !part.removed\" style=\"display: inline; white-space: pre-wrap\">{{part.value}}</div>\n          </div>\n        </div>\n        <div v-else style=\"font-size:1.2em; white-space: pre-wrap\">{{results}}</div>\n      </n-card>\n\n      <template #description>\n        Загрузка\n      </template>\n    </n-spin>\n  </div>\n</template>\n\n<script setup>\n  import { NCard, NInput, NButton, NSpin, NSpace, NCheckbox } from 'naive-ui'\n</script>\n\n<script>\n      // #<!-- @input=\"handleInput\" -->\nimport {ref} from 'vue'\n\nimport { InferenceSession, env, Tensor } from 'onnxruntime-web';\n\nenv.wasm.wasmPaths = {\n  'ort-wasm.wasm': \"/js/ort-wasm.wasm\",\n  'ort-wasm-threaded.wasm':  \"/js/ort-wasm-threaded.wasm\",\n  'ort-wasm-simd.wasm':  \"/js/ort-wasm-simd.wasm\",\n  'ort-wasm-simd-threaded.wasm':  \"/js/ort-wasm-simd-threaded.wasm\",\n}\n// const model = require(\"../assets/model.onnx\")\n// import buffer from \"../assets/model2.onnx\";\n// console.log(buffer)\n\nconst session_promise =\n    fetch('https://storage.yandexcloud.net/misha-sh-objects/model2.onnx')\n        .then(response => response.arrayBuffer())\n        .then(buffer => {\n            return InferenceSession.create(buffer,\n                { executionProviders: ['wasm'] });\n        })\n\nimport { diffChars } from 'diff'\n\nimport { loadPyodide } from 'pyodide'\nconst pyodide_promise = loadPyodide({\n    indexURL: \"/pyodide/\",\n  });\n\n\nimport code from '../assets/code.py'\nexport default {\n  name: 'HelloWorld',\n  props: {\n  },\n  data() {\n    return {\n      input: \"\",\n      results: \"\",\n      results_diff: [],\n      showLoadingBar: ref(true),\n      show_diff: ref(true)\n    }\n  },\n  created() {\n    console.log(\"CREATED\")\n    async function run() {\n      console.log(\"RUN\")\n      const pyodide = await pyodide_promise;\n      await pyodide.loadPackage(\"micropip\")\n      const session = await session_promise;\n\n      async function infer(float32_array) {\n        const buf = float32_array.getBuffer(\"f32\")\n\n        const tensor = new Tensor('float32', buf.data, [1 , 32, 489]);\n        const prom = session.run({input: tensor});\n        const output = (await prom).output;\n        return Array.from(output.data)\n      }\n\n      await pyodide.registerJsModule(\"jsinfer\", {\n        \"infer\": infer\n      })\n      // console.log(await pyodide.runPythonAsync(code))\n      pyodide.globals.set('text', 'Тест.')\n      console.log(await pyodide.runPythonAsync(code + \"\\nawait infer_optimal(params, text)\"))\n    }\n    run().then(() => {\n      this.showLoadingBar = false;\n    })\n    pyodide_promise.then(pyodide => {\n      console.log(pyodide)\n\n    })\n  },\n  methods: {\n    async handleInput() {\n      this.showLoadingBar = true;\n\n      const inp = this.input;\n\n      const pyodide = await pyodide_promise;\n      pyodide.globals.set('text', inp)\n      const res = await pyodide.runPythonAsync(code + \"\\nawait infer_optimal(params, text)\")\n\n      this.results = res;\n      this.results_diff = diffChars(inp, res);\n\n      this.showLoadingBar = false;\n    },\n    clearPunctuation() {\n      this.input = this.input.replaceAll('.', '').replaceAll(',', '');\n    },\n  }\n}\n</script>\n\n<style scoped>\n\n</style>\n","import script from \"./Main.vue?vue&type=script&setup=true&lang=js\"\nexport * from \"./Main.vue?vue&type=script&setup=true&lang=js\"\n\nconst __exports__ = script;\n\nexport default __exports__","import { render } from \"./App.vue?vue&type=template&id=34947450\"\nimport script from \"./App.vue?vue&type=script&lang=js\"\nexport * from \"./App.vue?vue&type=script&lang=js\"\n\nimport \"./App.vue?vue&type=style&index=0&id=34947450&lang=css\"\n\nimport exportComponent from \"/home/misha-sh/projects/audio-ml/app-web/node_modules/vue-loader/dist/exportHelper.js\"\nconst __exports__ = /*#__PURE__*/exportComponent(script, [['render',render]])\n\nexport default __exports__","import { createApp } from 'vue'\nimport App from './App.vue'\n\nconst app = createApp(App)\napp.mount('#app')\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","var deferred = [];\n__webpack_require__.O = function(result, chunkIds, fn, priority) {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every(function(key) { return __webpack_require__.O[key](chunkIds[j]); })) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {\n\tvar getter = module && module.__esModule ?\n\t\tfunction() { return module['default']; } :\n\t\tfunction() { return module; };\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","var getProto = Object.getPrototypeOf ? function(obj) { return Object.getPrototypeOf(obj); } : function(obj) { return obj.__proto__; };\nvar leafPrototypes;\n// create a fake namespace object\n// mode & 1: value is a module id, require it\n// mode & 2: merge all properties of value into the ns\n// mode & 4: return value when already ns object\n// mode & 16: return value when it's Promise-like\n// mode & 8|1: behave like require\n__webpack_require__.t = function(value, mode) {\n\tif(mode & 1) value = this(value);\n\tif(mode & 8) return value;\n\tif(typeof value === 'object' && value) {\n\t\tif((mode & 4) && value.__esModule) return value;\n\t\tif((mode & 16) && typeof value.then === 'function') return value;\n\t}\n\tvar ns = Object.create(null);\n\t__webpack_require__.r(ns);\n\tvar def = {};\n\tleafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];\n\tfor(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {\n\t\tObject.getOwnPropertyNames(current).forEach(function(key) { def[key] = function() { return value[key]; }; });\n\t}\n\tdef['default'] = function() { return value; };\n\t__webpack_require__.d(ns, def);\n\treturn ns;\n};","// define getter functions for harmony exports\n__webpack_require__.d = function(exports, definition) {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = function(chunkId) {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce(function(promises, key) {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks\n__webpack_require__.u = function(chunkId) {\n\t// return url for filenames based on template\n\treturn \"js/\" + chunkId + \".\" + {\"50\":\"12e0a2e8\",\"333\":\"00900aa8\",\"401\":\"cf235e46\",\"406\":\"89745463\",\"488\":\"3fecd343\",\"617\":\"00010a79\",\"772\":\"d97d8066\",\"949\":\"57677d72\",\"950\":\"02155d1c\"}[chunkId] + \".js\";\n};","// This function allow to reference async chunks\n__webpack_require__.miniCssF = function(chunkId) {\n\t// return url for filenames based on template\n\treturn undefined;\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = function(obj, prop) { return Object.prototype.hasOwnProperty.call(obj, prop); }","var inProgress = {};\nvar dataWebpackPrefix = \"app-web:\";\n// loadScript function to load a script via script tag\n__webpack_require__.l = function(url, done, key, chunkId) {\n\tif(inProgress[url]) { inProgress[url].push(done); return; }\n\tvar script, needAttach;\n\tif(key !== undefined) {\n\t\tvar scripts = document.getElementsByTagName(\"script\");\n\t\tfor(var i = 0; i < scripts.length; i++) {\n\t\t\tvar s = scripts[i];\n\t\t\tif(s.getAttribute(\"src\") == url || s.getAttribute(\"data-webpack\") == dataWebpackPrefix + key) { script = s; break; }\n\t\t}\n\t}\n\tif(!script) {\n\t\tneedAttach = true;\n\t\tscript = document.createElement('script');\n\n\t\tscript.charset = 'utf-8';\n\t\tscript.timeout = 120;\n\t\tif (__webpack_require__.nc) {\n\t\t\tscript.setAttribute(\"nonce\", __webpack_require__.nc);\n\t\t}\n\t\tscript.setAttribute(\"data-webpack\", dataWebpackPrefix + key);\n\t\tscript.src = url;\n\t}\n\tinProgress[url] = [done];\n\tvar onScriptComplete = function(prev, event) {\n\t\t// avoid mem leaks in IE.\n\t\tscript.onerror = script.onload = null;\n\t\tclearTimeout(timeout);\n\t\tvar doneFns = inProgress[url];\n\t\tdelete inProgress[url];\n\t\tscript.parentNode && script.parentNode.removeChild(script);\n\t\tdoneFns && doneFns.forEach(function(fn) { return fn(event); });\n\t\tif(prev) return prev(event);\n\t}\n\tvar timeout = setTimeout(onScriptComplete.bind(null, undefined, { type: 'timeout', target: script }), 120000);\n\tscript.onerror = onScriptComplete.bind(null, script.onerror);\n\tscript.onload = onScriptComplete.bind(null, script.onload);\n\tneedAttach && document.head.appendChild(script);\n};","// define __esModule on exports\n__webpack_require__.r = function(exports) {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.p = \"/\";","// no baseURI\n\n// object to store loaded and loading chunks\n// undefined = chunk not loaded, null = chunk preloaded/prefetched\n// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded\nvar installedChunks = {\n\t143: 0\n};\n\n__webpack_require__.f.j = function(chunkId, promises) {\n\t\t// JSONP chunk loading for javascript\n\t\tvar installedChunkData = __webpack_require__.o(installedChunks, chunkId) ? installedChunks[chunkId] : undefined;\n\t\tif(installedChunkData !== 0) { // 0 means \"already installed\".\n\n\t\t\t// a Promise means \"currently loading\".\n\t\t\tif(installedChunkData) {\n\t\t\t\tpromises.push(installedChunkData[2]);\n\t\t\t} else {\n\t\t\t\tif(true) { // all chunks have JS\n\t\t\t\t\t// setup Promise in chunk cache\n\t\t\t\t\tvar promise = new Promise(function(resolve, reject) { installedChunkData = installedChunks[chunkId] = [resolve, reject]; });\n\t\t\t\t\tpromises.push(installedChunkData[2] = promise);\n\n\t\t\t\t\t// start chunk loading\n\t\t\t\t\tvar url = __webpack_require__.p + __webpack_require__.u(chunkId);\n\t\t\t\t\t// create error before stack unwound to get useful stacktrace later\n\t\t\t\t\tvar error = new Error();\n\t\t\t\t\tvar loadingEnded = function(event) {\n\t\t\t\t\t\tif(__webpack_require__.o(installedChunks, chunkId)) {\n\t\t\t\t\t\t\tinstalledChunkData = installedChunks[chunkId];\n\t\t\t\t\t\t\tif(installedChunkData !== 0) installedChunks[chunkId] = undefined;\n\t\t\t\t\t\t\tif(installedChunkData) {\n\t\t\t\t\t\t\t\tvar errorType = event && (event.type === 'load' ? 'missing' : event.type);\n\t\t\t\t\t\t\t\tvar realSrc = event && event.target && event.target.src;\n\t\t\t\t\t\t\t\terror.message = 'Loading chunk ' + chunkId + ' failed.\\n(' + errorType + ': ' + realSrc + ')';\n\t\t\t\t\t\t\t\terror.name = 'ChunkLoadError';\n\t\t\t\t\t\t\t\terror.type = errorType;\n\t\t\t\t\t\t\t\terror.request = realSrc;\n\t\t\t\t\t\t\t\tinstalledChunkData[1](error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\t\t\t\t\t__webpack_require__.l(url, loadingEnded, \"chunk-\" + chunkId, chunkId);\n\t\t\t\t} else installedChunks[chunkId] = 0;\n\t\t\t}\n\t\t}\n};\n\n// no prefetching\n\n// no preloaded\n\n// no HMR\n\n// no HMR manifest\n\n__webpack_require__.O.j = function(chunkId) { return installedChunks[chunkId] === 0; };\n\n// install a JSONP callback for chunk loading\nvar webpackJsonpCallback = function(parentChunkLoadingFunction, data) {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\t// add \"moreModules\" to the modules object,\n\t// then flag all \"chunkIds\" as loaded and fire callback\n\tvar moduleId, chunkId, i = 0;\n\tif(chunkIds.some(function(id) { return installedChunks[id] !== 0; })) {\n\t\tfor(moduleId in moreModules) {\n\t\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t\t}\n\t\t}\n\t\tif(runtime) var result = runtime(__webpack_require__);\n\t}\n\tif(parentChunkLoadingFunction) parentChunkLoadingFunction(data);\n\tfor(;i < chunkIds.length; i++) {\n\t\tchunkId = chunkIds[i];\n\t\tif(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {\n\t\t\tinstalledChunks[chunkId][0]();\n\t\t}\n\t\tinstalledChunks[chunkId] = 0;\n\t}\n\treturn __webpack_require__.O(result);\n}\n\nvar chunkLoadingGlobal = self[\"webpackChunkapp_web\"] = self[\"webpackChunkapp_web\"] || [];\nchunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));\nchunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));","// startup\n// Load entry module and return exports\n// This entry module depends on other loaded chunks and execution need to be delayed\nvar __webpack_exports__ = __webpack_require__.O(undefined, [998], function() { return __webpack_require__(7978); })\n__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n"],"names":["_createBlock","_component_Main","env","session_promise","fetch","then","response","arrayBuffer","buffer","InferenceSession","executionProviders","pyodide_promise","loadPyodide","indexURL","__default__","name","props","data","input","results","results_diff","showLoadingBar","ref","show_diff","created","async","run","console","log","pyodide","loadPackage","session","infer","float32_array","buf","getBuffer","tensor","Tensor","prom","output","Array","from","registerJsModule","globals","set","runPythonAsync","code","this","methods","inp","res","diffChars","clearPunctuation","replaceAll","__exports__","components","Main","render","app","createApp","App","mount","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","undefined","exports","module","__webpack_modules__","m","deferred","O","result","chunkIds","fn","priority","notFulfilled","Infinity","i","length","fulfilled","j","Object","keys","every","key","splice","r","n","getter","__esModule","d","a","leafPrototypes","getProto","getPrototypeOf","obj","__proto__","t","value","mode","ns","create","def","current","indexOf","getOwnPropertyNames","forEach","definition","o","defineProperty","enumerable","get","f","e","chunkId","Promise","all","reduce","promises","u","miniCssF","g","globalThis","Function","window","prop","prototype","hasOwnProperty","call","inProgress","dataWebpackPrefix","l","url","done","push","script","needAttach","scripts","document","getElementsByTagName","s","getAttribute","createElement","charset","timeout","nc","setAttribute","src","onScriptComplete","prev","event","onerror","onload","clearTimeout","doneFns","parentNode","removeChild","setTimeout","bind","type","target","head","appendChild","Symbol","toStringTag","p","installedChunks","installedChunkData","promise","resolve","reject","error","Error","loadingEnded","errorType","realSrc","message","request","webpackJsonpCallback","parentChunkLoadingFunction","moreModules","runtime","some","id","chunkLoadingGlobal","self","__webpack_exports__"],"sourceRoot":""}